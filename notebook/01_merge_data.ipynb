{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74419b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA = \"data\"  # adapte si besoin\n",
    "Y_TRAIN = os.path.join(DATA, \"Y_train_1rknArQ.csv\")\n",
    "\n",
    "# Fichiers attendus\n",
    "FILES = {\n",
    "    \"train_home_team\": os.path.join(DATA, \"train_home_team_statistics_df.csv\"),\n",
    "    \"train_away_team\": os.path.join(DATA, \"train_away_team_statistics_df.csv\"),\n",
    "    \"train_home_player\": os.path.join(DATA, \"train_home_player_statistics_df.csv\"),\n",
    "    \"train_away_player\": os.path.join(DATA, \"train_away_player_statistics_df.csv\"),\n",
    "    \"test_home_team\": os.path.join(DATA, \"test_home_team_statistics_df.csv\"),\n",
    "    \"test_away_team\": os.path.join(DATA, \"test_away_team_statistics_df.csv\"),\n",
    "    \"test_home_player\": os.path.join(DATA, \"test_home_player_statistics_df.csv\"),\n",
    "    \"test_away_player\": os.path.join(DATA, \"test_away_player_statistics_df.csv\"),\n",
    "}\n",
    "\n",
    "def read_optional(path: str) -> pd.DataFrame | None:\n",
    "    return pd.read_csv(path) if os.path.exists(path) else None\n",
    "\n",
    "def detect_key(*dfs: pd.DataFrame) -> str:\n",
    "    \"\"\"Trouve une cl√© commune (GAME_ID/MATCH_ID/...) de fa√ßon heuristique.\"\"\"\n",
    "    commons = None\n",
    "    for df in dfs:\n",
    "        if df is None: \n",
    "            continue\n",
    "        cols = set(df.columns)\n",
    "        commons = cols if commons is None else commons & cols\n",
    "    if not commons:\n",
    "        raise ValueError(\"Aucune colonne commune trouv√©e pour la jointure.\")\n",
    "    # score les colonnes probables\n",
    "    def score(c: str) -> int:\n",
    "        cl = c.lower()\n",
    "        s = 0\n",
    "        if \"game\" in cl or \"match\" in cl: s += 3\n",
    "        if \"id\" in cl: s += 2\n",
    "        return s\n",
    "    candidates = sorted(list(commons), key=lambda c: (score(c), c.lower()), reverse=True)\n",
    "    return candidates[0]\n",
    "\n",
    "def add_prefix_except_key(df: pd.DataFrame, prefix: str, key: str) -> pd.DataFrame:\n",
    "    if df is None:\n",
    "        return None\n",
    "    ren = {c: f\"{prefix}{c}\" for c in df.columns if c != key}\n",
    "    return df.rename(columns=ren)\n",
    "\n",
    "def keep_numeric_plus_id(df: pd.DataFrame, id_col: str) -> pd.DataFrame:\n",
    "    num = df.select_dtypes(include=[\"number\"]).astype(\"float32\")\n",
    "    if id_col in df.columns and id_col not in num.columns:\n",
    "        num = pd.concat([df[[id_col]], num], axis=1)\n",
    "    return num\n",
    "\n",
    "# --- Chargement\n",
    "th = pd.read_csv(FILES[\"train_home_team\"])\n",
    "ta = pd.read_csv(FILES[\"train_away_team\"])\n",
    "tph = read_optional(FILES[\"train_home_player\"])\n",
    "tpa = read_optional(FILES[\"train_away_player\"])\n",
    "\n",
    "vh = pd.read_csv(FILES[\"test_home_team\"])\n",
    "va = pd.read_csv(FILES[\"test_away_team\"])\n",
    "vph = read_optional(FILES[\"test_home_player\"])\n",
    "vpa = read_optional(FILES[\"test_away_player\"])\n",
    "\n",
    "# --- D√©tection cl√©\n",
    "key = detect_key(th, ta, tph, tpa, vh, va, vph, vpa)\n",
    "print(f\"üîë Cl√© d√©tect√©e: {key}\")\n",
    "\n",
    "# --- Pr√©fixes\n",
    "th, ta = add_prefix_except_key(th, \"home_team_\", key), add_prefix_except_key(ta, \"away_team_\", key)\n",
    "if tph is not None: tph = add_prefix_except_key(tph, \"home_player_\", key)\n",
    "if tpa is not None: tpa = add_prefix_except_key(tpa, \"away_player_\", key)\n",
    "vh, va = add_prefix_except_key(vh, \"home_team_\", key), add_prefix_except_key(va, \"away_team_\", key)\n",
    "if vph is not None: vph = add_prefix_except_key(vph, \"home_player_\", key)\n",
    "if vpa is not None: vpa = add_prefix_except_key(vpa, \"away_player_\", key)\n",
    "\n",
    "# --- Merge TRAIN\n",
    "train = th.merge(ta, on=key, how=\"inner\", validate=\"one_to_one\")\n",
    "if tph is not None:\n",
    "    train = train.merge(tph, on=key, how=\"left\")\n",
    "if tpa is not None:\n",
    "    train = train.merge(tpa, on=key, how=\"left\")\n",
    "\n",
    "# --- Merge TEST\n",
    "test = vh.merge(va, on=key, how=\"inner\", validate=\"one_to_one\")\n",
    "if vph is not None:\n",
    "    test = test.merge(vph, on=key, how=\"left\")\n",
    "if vpa is not None:\n",
    "    test = test.merge(vpa, on=key, how=\"left\")\n",
    "\n",
    "# Uniformise l'ID\n",
    "if key != \"id\":\n",
    "    train = train.rename(columns={key: \"id\"})\n",
    "    test = test.rename(columns={key: \"id\"})\n",
    "id_col = \"id\"\n",
    "\n",
    "# Nettoyage colonnes vides/constantes (optionnel light)\n",
    "to_drop = [c for c in train.columns if c != id_col and train[c].nunique(dropna=False) <= 1]\n",
    "if to_drop:\n",
    "    train = train.drop(columns=to_drop)\n",
    "    test = test.drop(columns=[c for c in to_drop if c in test.columns], errors=\"ignore\")\n",
    "\n",
    "# Ne garder que num√©rique + id\n",
    "train = keep_numeric_plus_id(train, id_col)\n",
    "test  = keep_numeric_plus_id(test, id_col)\n",
    "\n",
    "print(\"‚úÖ shapes:\", train.shape, test.shape)\n",
    "\n",
    "# Sauvegarde X\n",
    "xtrain_path = os.path.join(DATA, \"x_train_merged.csv\")\n",
    "xtest_path  = os.path.join(DATA, \"x_test_merged.csv\")\n",
    "train.to_csv(xtrain_path, index=False)\n",
    "test.to_csv(xtest_path, index=False)\n",
    "print(f\"üíæ √âcrit: {xtrain_path} & {xtest_path}\")\n",
    "\n",
    "# Sauvegarde y (align√©)\n",
    "if os.path.exists(Y_TRAIN):\n",
    "    y = pd.read_csv(Y_TRAIN)\n",
    "    # d√©tecte id + colonnes cible\n",
    "    id_guess = None\n",
    "    for cand in [\"id\", \"row_id\", \"match_id\", \"game_id\", \"MATCH_ID\", \"GAME_ID\"]:\n",
    "        if cand in y.columns:\n",
    "            id_guess = cand; break\n",
    "    if id_guess is None:\n",
    "        id_guess = y.columns[0]\n",
    "    # nommage propre\n",
    "    cols = {id_guess: \"id\"}\n",
    "    for c in y.columns:\n",
    "        cl = c.lower()\n",
    "        if \"home\" in cl and \"prob\" not in cl: cols[c] = \"home\"\n",
    "        if \"draw\" in cl: cols[c] = \"draw\"\n",
    "        if \"away\" in cl: cols[c] = \"away\"\n",
    "    y = y.rename(columns=cols)\n",
    "    y = y[[\"id\",\"home\",\"draw\",\"away\"]].copy()\n",
    "    # filtre aux ids pr√©sents dans X train\n",
    "    y = y[y[\"id\"].isin(train[\"id\"])]\n",
    "    y.to_csv(os.path.join(DATA, \"y_train_aligned.csv\"), index=False)\n",
    "    print(\"üíæ √âcrit: data/y_train_aligned.csv\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è data/Y_train_1rknArQ.csv introuvable ‚Üí pas de y align√©.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\"../data/Y_train_1rknArQ.csv\")\n",
    "print(y_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2fca74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè† Home team columns: ['ID', 'LEAGUE', 'TEAM_NAME', 'TEAM_SHOTS_TOTAL_season_sum', 'TEAM_SHOTS_INSIDEBOX_season_sum', 'TEAM_SHOTS_OFF_TARGET_season_sum', 'TEAM_SHOTS_ON_TARGET_season_sum', 'TEAM_SHOTS_OUTSIDEBOX_season_sum', 'TEAM_PASSES_season_sum', 'TEAM_SUCCESSFUL_PASSES_season_sum']\n",
      "üö© Away team columns: ['ID', 'LEAGUE', 'TEAM_NAME', 'TEAM_SHOTS_TOTAL_season_sum', 'TEAM_SHOTS_INSIDEBOX_season_sum', 'TEAM_SHOTS_OFF_TARGET_season_sum', 'TEAM_SHOTS_ON_TARGET_season_sum', 'TEAM_SHOTS_OUTSIDEBOX_season_sum', 'TEAM_PASSES_season_sum', 'TEAM_SUCCESSFUL_PASSES_season_sum']\n",
      "üë§ Home player columns: ['ID', 'LEAGUE', 'TEAM_NAME', 'POSITION', 'PLAYER_NAME', 'PLAYER_ACCURATE_CROSSES_season_sum', 'PLAYER_ACCURATE_PASSES_season_sum', 'PLAYER_AERIALS_WON_season_sum', 'PLAYER_ASSISTS_season_sum', 'PLAYER_BIG_CHANCES_CREATED_season_sum']\n",
      "üë• Away player columns: ['ID', 'LEAGUE', 'TEAM_NAME', 'POSITION', 'PLAYER_NAME', 'PLAYER_ACCURATE_CROSSES_season_sum', 'PLAYER_ACCURATE_PASSES_season_sum', 'PLAYER_AERIALS_WON_season_sum', 'PLAYER_ASSISTS_season_sum', 'PLAYER_BIG_CHANCES_CREATED_season_sum']\n",
      "\n",
      "üîë Colonnes communes entre les 4 fichiers: {'TEAM_NAME', 'ID', 'LEAGUE'}\n"
     ]
    }
   ],
   "source": [
    "#connaitre la cl√© de jointure \n",
    "import os\n",
    "import pandas as pd\n",
    "DATA = \"../data\"\n",
    "Y_TRAIN = os.path.join(DATA, \"Y_train_1rknArQ.csv\")\n",
    "\n",
    "FILES = {\n",
    "    \"train_home_team\": os.path.join(DATA, \"train_home_team_statistics_df.csv\"),\n",
    "    \"train_away_team\": os.path.join(DATA, \"train_away_team_statistics_df.csv\"),\n",
    "    \"train_home_player\": os.path.join(DATA, \"train_home_player_statistics_df.csv\"),\n",
    "    \"train_away_player\": os.path.join(DATA, \"train_away_player_statistics_df.csv\"),\n",
    "}\n",
    "# Lis les 4 tables du train\n",
    "home_team = pd.read_csv(FILES[\"train_home_team\"])\n",
    "away_team = pd.read_csv(FILES[\"train_away_team\"])\n",
    "home_player = pd.read_csv(FILES[\"train_home_player\"])\n",
    "away_player = pd.read_csv(FILES[\"train_away_player\"])\n",
    "\n",
    "\n",
    "# Affiche les noms de colonnes\n",
    "print(\"üè† Home team columns:\", list(home_team.columns)[:10])\n",
    "print(\"üö© Away team columns:\", list(away_team.columns)[:10])\n",
    "print(\"üë§ Home player columns:\", list(home_player.columns)[:10])\n",
    "print(\"üë• Away player columns:\", list(away_player.columns)[:10])\n",
    "\n",
    "# Trouve les colonnes communes\n",
    "common = set(home_team.columns) & set(away_team.columns) & set(home_player.columns) & set(away_player.columns)\n",
    "print(\"\\nüîë Colonnes communes entre les 4 fichiers:\", common)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "441a3d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home_team: 12303/12303 IDs uniques\n",
      "away_team: 12303/12303 IDs uniques\n",
      "home_player: 12303/237079 IDs uniques\n",
      " -> Plusieurs lignes par match (ID)\n",
      "away_player: 12303/236132 IDs uniques\n",
      " -> Plusieurs lignes par match (ID)\n"
     ]
    }
   ],
   "source": [
    "def check_key(df, name):\n",
    "    n = len(df)\n",
    "    u = df['ID'].nunique()\n",
    "    print(f\"{name}: {u}/{n} IDs uniques\")\n",
    "    if u != n:\n",
    "        print(\" -> Plusieurs lignes par match (ID)\")\n",
    "\n",
    "check_key(home_team,  \"home_team\")\n",
    "check_key(away_team,  \"away_team\")\n",
    "check_key(home_player,\"home_player\")\n",
    "check_key(away_player,\"away_player\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e3592da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def aggregate_player_stats(df, prefix):\n",
    "    \"\"\"Agr√®ge les stats d'un fichier joueur au niveau du match (ID).\"\"\"\n",
    "    # garder seulement les colonnes num√©riques\n",
    "    num = df.select_dtypes(include=['number']).copy()\n",
    "    if 'ID' not in num.columns:\n",
    "        num = num.join(df['ID'])\n",
    "    num = num.set_index('ID')\n",
    "\n",
    "    # Calcul des statistiques agr√©g√©es (moyenne, somme et √©cart-type)\n",
    "    agg = num.groupby(level=0).agg(['mean', 'sum', 'std'])\n",
    "    # aplatir les multi-index\n",
    "    agg.columns = [f\"{prefix}{c}_{stat}\" for c, stat in agg.columns]\n",
    "    agg = agg.reset_index()\n",
    "    return agg\n",
    "\n",
    "home_player_agg = aggregate_player_stats(home_player, \"home_player_\")\n",
    "away_player_agg = aggregate_player_stats(away_player, \"away_player_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "158d6d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fusion compl√®te : (12303, 2097)\n"
     ]
    }
   ],
   "source": [
    "# Renommer les colonnes team pour √©viter les collisions\n",
    "def rename_with_prefix(df, prefix):\n",
    "    return df.rename(columns={c: f\"{prefix}{c}\" for c in df.columns if c != \"ID\"})\n",
    "\n",
    "home_team_ren = rename_with_prefix(home_team, \"home_team_\")\n",
    "away_team_ren = rename_with_prefix(away_team, \"away_team_\")\n",
    "\n",
    "# Jointure sur ID\n",
    "train_df = (\n",
    "    home_team_ren\n",
    "    .merge(away_team_ren, on=\"ID\", how=\"inner\")\n",
    "    .merge(home_player_agg, on=\"ID\", how=\"left\")\n",
    "    .merge(away_player_agg, on=\"ID\", how=\"left\")\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Fusion compl√®te :\", train_df.shape)\n",
    "train_df.to_csv(\"../data/x_train_full.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f34bf5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12303 entries, 0 to 12302\n",
      "Columns: 2097 entries, ID to away_player_PLAYER_SHOTS_OFF_TARGET_5_last_match_std_std\n",
      "dtypes: float64(2092), int64(1), object(4)\n",
      "memory usage: 196.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.head()\n",
    "train_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37dea999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes texte : ['home_team_LEAGUE', 'home_team_TEAM_NAME', 'away_team_LEAGUE', 'away_team_TEAM_NAME']\n"
     ]
    }
   ],
   "source": [
    "text_cols = train_df.select_dtypes(include=['object']).columns\n",
    "print(\"Colonnes texte :\", text_cols.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ecf0063",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=text_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77d62053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ x_train_clean.csv pr√™t pour l'entra√Ænement : (12303, 2093)\n"
     ]
    }
   ],
   "source": [
    "train_df.to_csv(\"../data/x_train_clean.csv\", index=False)\n",
    "print(\"‚úÖ x_train_clean.csv pr√™t pour l'entra√Ænement :\", train_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "620c9e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fusion test compl√®te : (25368, 2093)\n"
     ]
    }
   ],
   "source": [
    "home_team_test = pd.read_csv(\"../data/test_home_team_statistics_df.csv\")\n",
    "away_team_test = pd.read_csv(\"../data/test_away_team_statistics_df.csv\")\n",
    "home_player_test = pd.read_csv(\"../data/test_home_player_statistics_df.csv\")\n",
    "away_player_test = pd.read_csv(\"../data/test_away_player_statistics_df.csv\")\n",
    "\n",
    "home_player_test_agg = aggregate_player_stats(home_player_test, \"home_player_\")\n",
    "away_player_test_agg = aggregate_player_stats(away_player_test, \"away_player_\")\n",
    "\n",
    "home_team_test_ren = rename_with_prefix(home_team_test, \"home_team_\")\n",
    "away_team_test_ren = rename_with_prefix(away_team_test, \"away_team_\")\n",
    "\n",
    "test_df = (\n",
    "    home_team_test_ren\n",
    "    .merge(away_team_test_ren, on=\"ID\", how=\"inner\")\n",
    "    .merge(home_player_test_agg, on=\"ID\", how=\"left\")\n",
    "    .merge(away_player_test_agg, on=\"ID\", how=\"left\")\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Fusion test compl√®te :\", test_df.shape)\n",
    "test_df.to_csv(\"../data/x_test_full.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4a1acf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train matches: 12303\n",
      "Test matches: 25368\n"
     ]
    }
   ],
   "source": [
    "print(\"Train matches:\", train_df[\"ID\"].nunique())\n",
    "print(\"Test matches:\", test_df[\"ID\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c53e0417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes align√©es: (12303, 2093) (25368, 2093)\n",
      "‚úÖ Sauv√©: data/x_train_clean.csv, data/x_test_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charge tes fusions compl√®tes\n",
    "train_df = pd.read_csv(\"../data/x_train_full.csv\")\n",
    "test_df  = pd.read_csv(\"../data/x_test_full.csv\")\n",
    "\n",
    "# 1) Drop colonnes non num√©riques (texte) + garder id\n",
    "obj_cols = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "obj_cols = [c for c in obj_cols if c != 'ID']   # on garde ID\n",
    "train_df = train_df.drop(columns=obj_cols, errors='ignore')\n",
    "test_df  = test_df.drop(columns=obj_cols, errors='ignore')\n",
    "\n",
    "# 2) Renommer ID -> id\n",
    "train_df = train_df.rename(columns={'ID':'id'})\n",
    "test_df  = test_df.rename(columns={'ID':'id'})\n",
    "\n",
    "# 3) Aligner EXACTEMENT les colonnes (sauf 'id')\n",
    "train_cols = set(train_df.columns) - {'id'}\n",
    "test_cols  = set(test_df.columns) - {'id'}\n",
    "common     = ['id'] + sorted(list(train_cols & test_cols))\n",
    "\n",
    "X_train = train_df[common].copy()\n",
    "X_test  = test_df[common].copy()\n",
    "\n",
    "print(\"Shapes align√©es:\", X_train.shape, X_test.shape)\n",
    "\n",
    "# 4) Sauvegarde clean\n",
    "X_train.to_csv(\"../data/x_train_clean.csv\", index=False)\n",
    "X_test.to_csv(\"../data/x_test_clean.csv\", index=False)\n",
    "print(\"‚úÖ Sauv√©: data/x_train_clean.csv, data/x_test_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a325c74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sauv√©: ../data/y_train_aligned.csv, ../data/y_target.csv (12303, 4) (12303,)\n"
     ]
    }
   ],
   "source": [
    "y = pd.read_csv(\"../data/Y_train_1rknArQ.csv\")\n",
    "\n",
    "# d√©tecter la colonne id et renommer\n",
    "id_col = None\n",
    "for cand in [\"id\",\"ID\",\"row_id\",\"match_id\",\"game_id\",\"MATCH_ID\",\"GAME_ID\"]:\n",
    "    if cand in y.columns:\n",
    "        id_col = cand; break\n",
    "if id_col is None: id_col = y.columns[0]\n",
    "y = y.rename(columns={id_col:'id'})\n",
    "\n",
    "# s‚Äôassurer d‚Äôavoir bien les 3 colonnes probas\n",
    "ren = {}\n",
    "for c in y.columns:\n",
    "    cl = c.lower()\n",
    "    if \"home\" in cl and \"prob\" not in cl: ren[c] = \"home\"\n",
    "    elif \"draw\" in cl: ren[c] = \"draw\"\n",
    "    elif \"away\" in cl: ren[c] = \"away\"\n",
    "y = y.rename(columns=ren)[[\"id\",\"home\",\"draw\",\"away\"]]\n",
    "\n",
    "# filtrer sur les ids pr√©sents dans X_train\n",
    "y = y[y[\"id\"].isin(X_train[\"id\"])].copy()\n",
    "\n",
    "# classe 0/1/2 = argmax([home,draw,away])\n",
    "y_target = np.argmax(y[[\"home\",\"draw\",\"away\"]].values, axis=1)\n",
    "\n",
    "# Sauvegarde\n",
    "y.to_csv(\"../data/y_train_aligned.csv\", index=False)\n",
    "pd.DataFrame({\"id\": y[\"id\"], \"target\": y_target}).to_csv(\"../data/y_target.csv\", index=False)\n",
    "print(\"‚úÖ Sauv√©: ../data/y_train_aligned.csv, ../data/y_target.csv\", y.shape, y_target.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
