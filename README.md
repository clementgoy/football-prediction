- DonnÃ©es brutes dans `data/` (non versionnÃ©es dans git).
- EDA & protos dans `notebooks/`.
- Code dans `src/`.
- Suivi d'expÃ©: MLflow (par dÃ©faut local ./mlruns) + CSV `logs/experiments.csv`.

<strong>ğŸ§­ Vision dâ€™ensemble du pipeline complet : </strong>
Ã‰tape	Script utilisÃ©	RÃ´le
1. Fusion / Nettoyage brut:	merge_data.py	--> Construit train_merged.csv et test_merged.csv Ã  partir des 4Ã—2 CSV bruts
2. Construction X/y:	build_dataset.py + features.py	--> Nettoie, sÃ©lectionne les colonnes utiles, et prÃ©pare les matrices dâ€™entraÃ®nement
3. EntraÃ®nement modÃ¨le:	train.py + models.py + utils.py	--> EntraÃ®ne un Gradient Boosting (ou autre)
4. PrÃ©diction / Soumission:	predict.py	--> Utilise le modÃ¨le entraÃ®nÃ© pour prÃ©dire sur test_merged.csv


<strong>RÃ´le central de merge_data.py</strong>

Câ€™est le cÅ“ur du pipeline de prÃ©paration des donnÃ©es.
Il remplace et englobe plusieurs fonctions que tu aurais pu coder Ã  la main avant.

ğŸ” En rÃ©sumÃ©, il fait :

Lecture automatique de tous les fichiers CSV bruts du challenge (home/away Ã— team/player).

Nettoyage â†’ suppression des doublons, harmonisation, tri par ID.

AgrÃ©gation â†’ combine les donnÃ©es des joueurs (sum/mean/std par match).

Fusion complÃ¨te â†’ jointure des 4 tables sur ID.

Ajout des labels Y_train (si fournis).

Sauvegarde â†’ Ã©crit deux fichiers finaux :

    - train_merged.csv

    - test_merged.csv

    - un petit schema.json rÃ©capitulatif (noms, dimensionsâ€¦).

